{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91729542",
   "metadata": {},
   "source": [
    "# Resultados de Modelado y Comparación de Algoritmos\n",
    "\n",
    "En esta sección se presentan los resultados obtenidos a partir del entrenamiento y evaluación de distintos modelos de clasificación supervisada, aplicados al dataset final preparado (`data_set_base`).  \n",
    "El objetivo del modelado es **predecir el incumplimiento de pago de un cliente (`TARGET = 1`)**, considerando un escenario altamente desbalanceado, donde aproximadamente un 8% de los registros corresponden a clientes morosos.\n",
    "\n",
    "Para la evaluación se utilizaron las siguientes métricas:\n",
    "\n",
    "- **Precision (clase 1)**: proporción de clientes clasificados como morosos que efectivamente lo son.\n",
    "- **Recall (clase 1)**: capacidad del modelo para detectar clientes morosos.\n",
    "- **F1-score (clase 1)**: equilibrio entre precisión y recall.\n",
    "- **Accuracy**: proporción total de predicciones correctas.\n",
    "- **ROC AUC**: capacidad global del modelo para discriminar entre clientes morosos y no morosos, independiente del umbral.\n",
    "\n",
    "Dado el contexto de riesgo crediticio, se prioriza **Recall y ROC AUC** por sobre Accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## Regresión Logística\n",
    "\n",
    "### Regresión Logística con `class_weight='balanced'`\n",
    "\n",
    "- **ROC AUC:** ~0.63  \n",
    "- **Recall clase 1:** ~0.55  \n",
    "- **Precision clase 1:** ~0.12  \n",
    "\n",
    "Este modelo logra identificar aproximadamente la mitad de los clientes morosos, pero con una precisión muy baja, lo que implica una gran cantidad de falsos positivos.  \n",
    "Al tratarse de un modelo lineal, su capacidad para capturar relaciones complejas entre variables es limitada.\n",
    "\n",
    "**Conclusión:**  \n",
    "Modelo adecuado como **baseline explicativo**, pero no competitivo en términos de desempeño predictivo.\n",
    "\n",
    "---\n",
    "\n",
    "### Regresión Logística + SMOTE\n",
    "\n",
    "Los resultados obtenidos con SMOTE fueron prácticamente equivalentes a los del modelo balanceado, sin mejoras relevantes en ROC AUC ni en F1-score.\n",
    "\n",
    "**Conclusión:**  \n",
    "El sobremuestreo no mejora el desempeño del modelo lineal en este caso.\n",
    "\n",
    "---\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "### Random Forest con `class_weight='balanced'`\n",
    "\n",
    "- **ROC AUC:** ~0.766  \n",
    "- **Recall clase 1:** ~0.52  \n",
    "- **Precision clase 1:** ~0.22  \n",
    "\n",
    "Este modelo presenta una mejora clara respecto a la regresión logística, capturando relaciones no lineales y mejorando la discriminación global.  \n",
    "Sin embargo, el recall sigue siendo moderado y el modelo tiende a privilegiar la clase mayoritaria.\n",
    "\n",
    "**Conclusión:**  \n",
    "Buen modelo de referencia, pero no el mejor para maximizar detección de riesgo.\n",
    "\n",
    "---\n",
    "\n",
    "### Random Forest + SMOTE\n",
    "\n",
    "El uso de SMOTE en Random Forest generó un comportamiento indeseado:  \n",
    "- Recall extremadamente bajo en la clase minoritaria.\n",
    "- El modelo termina clasificando casi todos los casos como clase 0.\n",
    "\n",
    "**Conclusión:**  \n",
    "SMOTE no resulta adecuado en combinación con Random Forest para este dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### Ajuste de Umbral en Random Forest\n",
    "\n",
    "Se evaluaron distintos umbrales de decisión.  \n",
    "Aunque valores bajos del umbral aumentan levemente el recall, el F1-score se mantiene bajo y el modelo pierde estabilidad.\n",
    "\n",
    "**Conclusión:**  \n",
    "El ajuste de umbral no logra compensar las limitaciones estructurales del modelo.\n",
    "\n",
    "---\n",
    "\n",
    "## Gradient Boosting (sklearn)\n",
    "\n",
    "- **ROC AUC:** ~0.768  \n",
    "- **Recall clase 1:** ~0.02  \n",
    "\n",
    "A pesar de un buen ROC AUC, el modelo prácticamente no detecta clientes morosos, clasificando la gran mayoría de los registros como clase 0.\n",
    "\n",
    "**Conclusión:**  \n",
    "Modelo descartado para el problema de riesgo crediticio.\n",
    "\n",
    "---\n",
    "\n",
    "## XGBoost\n",
    "\n",
    "- **ROC AUC:** ~0.776  \n",
    "- **Recall clase 1:** ~0.69  \n",
    "- **Precision clase 1:** ~0.18  \n",
    "- **F1-score clase 1:** ~0.28  \n",
    "\n",
    "XGBoost muestra un equilibrio notable entre capacidad de discriminación y detección de clientes morosos.  \n",
    "Es capaz de identificar cerca del **70% de los clientes en incumplimiento**, manteniendo una accuracy razonable para un problema desbalanceado.\n",
    "\n",
    "**Conclusión:**  \n",
    "Modelo altamente competitivo y ampliamente utilizado en contextos reales de riesgo crediticio.\n",
    "\n",
    "---\n",
    "\n",
    "## LightGBM (Modelo con Mejor Desempeño)\n",
    "\n",
    "- **ROC AUC:** ~0.777  \n",
    "- **Recall clase 1:** ~0.68  \n",
    "- **Precision clase 1:** ~0.18  \n",
    "- **F1-score clase 1:** ~0.29  \n",
    "\n",
    "LightGBM presenta el **mejor desempeño global** entre todos los modelos evaluados.  \n",
    "Obtiene el mayor ROC AUC y un recall elevado para la clase minoritaria, con tiempos de entrenamiento eficientes y buena escalabilidad.\n",
    "\n",
    "**Conclusión:**  \n",
    "LightGBM se selecciona como **modelo final del proyecto**, al ofrecer el mejor balance entre:\n",
    "- Capacidad predictiva\n",
    "- Detección de clientes morosos\n",
    "- Robustez ante desbalance de clases\n",
    "\n",
    "---\n",
    "\n",
    "## Comparación Final de Modelos\n",
    "\n",
    "| Modelo | ROC AUC | Recall (Clase 1) | Comentario |\n",
    "|------|--------|------------------|-----------|\n",
    "| Regresión Logística | ~0.63 | ~0.55 | Baseline explicativo |\n",
    "| Random Forest | ~0.77 | ~0.52 | Buen benchmark |\n",
    "| Gradient Boosting | ~0.77 | 0.02 | No usable |\n",
    "| XGBoost | ~0.776 | ~0.69 | Muy competitivo |\n",
    "| **LightGBM** | **~0.777** | **~0.68** | Modelo final |\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusión General\n",
    "\n",
    "A partir del análisis comparativo, se concluye que los modelos basados en **boosting de árboles** superan consistentemente a los modelos lineales y a Random Forest en el contexto de este problema.  \n",
    "\n",
    "**LightGBM** es seleccionado como el modelo final, ya que:\n",
    "- Maximiza la capacidad de discriminación (ROC AUC).\n",
    "- Mantiene un alto recall para clientes morosos.\n",
    "- Es consistente con prácticas reales en la industria financiera.\n",
    "\n",
    "Este modelo se considera adecuado para su uso en un sistema de evaluación de riesgo crediticio.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
