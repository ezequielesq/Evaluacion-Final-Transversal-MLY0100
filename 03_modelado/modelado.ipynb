{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45d3cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf2fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_base = pd.read_parquet(\"../02_preparación de los datos/data_set_final.parquet\")\n",
    "\n",
    "print(data_set_base.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434399b",
   "metadata": {},
   "source": [
    "# Separacion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8204934",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_set_base.drop(columns=[\"TARGET\", \"SK_ID_CURR\"])\n",
    "y = data_set_base[\"TARGET\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73605aa5",
   "metadata": {},
   "source": [
    "# División del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2658226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Test:\", X_test.shape)\n",
    "print(\"Proporción default train:\", y_train.mean())\n",
    "print(\"Proporción default test:\", y_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40ada32",
   "metadata": {},
   "source": [
    "# Entrenamiento con regresión logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f08c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(max_iter=1000, class_weight=\"balanced\", n_jobs=-1)\n",
    "\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(X_test)\n",
    "y_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc05ed03",
   "metadata": {},
   "source": [
    "## Resultados de la Regresión Logística\n",
    "\n",
    "Con el objetivo de validar la calidad del dataset preparado y verificar la existencia de señal predictiva, se entrenó un modelo base de **Regresión Logística** utilizando el conjunto de datos final (`data_set_base`).  \n",
    "Debido al fuerte desbalance de la variable objetivo (`TARGET` ≈ 8% de incumplimiento), se utilizó el parámetro `class_weight=\"balanced\"` para priorizar la detección de la clase minoritaria.\n",
    "\n",
    "### Reporte de clasificación\n",
    "\n",
    "- **Clase 0 (clientes sin incumplimiento):**\n",
    "  - Alta precisión (0.94)\n",
    "  - Recall moderado (0.65)\n",
    "\n",
    "- **Clase 1 (clientes con incumplimiento):**\n",
    "  - Recall elevado (0.54), lo que indica que el modelo logra identificar más del 50% de los clientes en riesgo.\n",
    "  - Precisión baja (0.12), esperable en un contexto altamente desbalanceado.\n",
    "\n",
    "### Análisis e interpretación\n",
    "\n",
    "El valor de **ROC AUC = 0.63** confirma que el modelo presenta una capacidad de discriminación superior al azar, lo cual es especialmente relevante considerando que se trata de un modelo lineal simple y sin optimización de hiperparámetros.  \n",
    "Este resultado valida que el proceso de preparación de datos fue exitoso y permitió capturar patrones significativos asociados al incumplimiento de pago.\n",
    "\n",
    "Desde una perspectiva de negocio, el **recall de la clase positiva** adquiere mayor relevancia que la precisión, dado que el costo de aprobar a un cliente riesgoso es superior al de rechazar a un cliente solvente. En este sentido, el desempeño del modelo es consistente con los objetivos del análisis de riesgo crediticio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef11c2a7",
   "metadata": {},
   "source": [
    "# Entrenamiento con regresión logisita ajustado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4f97f9",
   "metadata": {},
   "source": [
    "## Entrenamiendo con class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "512eab61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression (class_weight='balanced') ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.64      0.76     70672\n",
      "           1       0.12      0.55      0.19      6206\n",
      "\n",
      "    accuracy                           0.63     76878\n",
      "   macro avg       0.53      0.59      0.48     76878\n",
      "weighted avg       0.88      0.63      0.72     76878\n",
      "\n",
      "ROC AUC: 0.6303116389005039\n"
     ]
    }
   ],
   "source": [
    "lr_balanced = LogisticRegression(\n",
    "    max_iter=3000,\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"lbfgs\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lr_balanced.fit(X_train, y_train)\n",
    "\n",
    "y_proba_lr = lr_balanced.predict_proba(X_test)[:, 1]\n",
    "y_pred_lr = (y_proba_lr >= 0.5).astype(int)\n",
    "\n",
    "print(\"=== Logistic Regression (class_weight='balanced') ===\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5303cd8",
   "metadata": {},
   "source": [
    "## Entrenamiento con SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f07ecf90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression + SMOTE ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.63      0.76     70672\n",
      "           1       0.12      0.56      0.19      6206\n",
      "\n",
      "    accuracy                           0.63     76878\n",
      "   macro avg       0.53      0.60      0.48     76878\n",
      "weighted avg       0.88      0.63      0.71     76878\n",
      "\n",
      "ROC AUC: 0.6301170815326861\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "lr_smote = LogisticRegression(\n",
    "    max_iter=3000,\n",
    "    solver=\"lbfgs\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lr_smote.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "y_proba_lr_sm = lr_smote.predict_proba(X_test)[:, 1]\n",
    "y_pred_lr_sm = (y_proba_lr_sm >= 0.5).astype(int)\n",
    "\n",
    "print(\"=== Logistic Regression + SMOTE ===\")\n",
    "print(classification_report(y_test, y_pred_lr_sm))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_lr_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301a65aa",
   "metadata": {},
   "source": [
    "# Entrenamiento con Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e62748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables predictoras y objetivo\n",
    "X = data_set_base.drop(columns=[\"TARGET\", \"SK_ID_CURR\"])\n",
    "y = data_set_base[\"TARGET\"]\n",
    "\n",
    "# Train / Test split estratificado\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab126147",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=50,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed1ac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "y_pred = rf.predict(X_test)\n",
    "y_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Métricas\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c4524",
   "metadata": {},
   "source": [
    "## Resultados de Random Forest\n",
    "\n",
    "El objetivo de este modelo es predecir la probabilidad de incumplimiento de pago (`TARGET = 1`) de un cliente, utilizando el dataset integrado y preparado (`data_set_base`), el cual incorpora información:\n",
    "\n",
    "- Socioeconómica del cliente (application)\n",
    "- Historial crediticio (bureau, bureau_balance)\n",
    "- Créditos previos (previous_application)\n",
    "- Comportamiento de pago (pos_cash, installments)\n",
    "- Uso de tarjetas de crédito (credit_card_balance)\n",
    "\n",
    "---\n",
    "\n",
    "### Justificación del uso de Random Forest\n",
    "\n",
    "Se seleccionó Random Forest como modelo debido a que:\n",
    "\n",
    "- Captura relaciones no lineales entre variables explicativas y el riesgo crediticio.\n",
    "- Es robusto frente a multicolinealidad, outliers y ruido residual.\n",
    "- Maneja adecuadamente datasets con alta dimensionalidad.\n",
    "- Es ampliamente utilizado en problemas reales de scoring crediticio.\n",
    "\n",
    "Dado que el comportamiento de pago depende de múltiples interacciones complejas (historial, montos, antigüedad, atrasos previos), un modelo lineal resulta insuficiente, justificando el uso de Random Forest.\n",
    "\n",
    "---\n",
    "\n",
    "### Configuración general del modelo\n",
    "\n",
    "El modelo fue entrenado utilizando:\n",
    "\n",
    "- División train/test estratificada.\n",
    "- Variable objetivo desbalanceada (~8% de incumplimiento).\n",
    "- Dataset previamente limpiado, imputado, codificado y escalado.\n",
    "- Sin técnicas de balanceo artificial, para preservar la distribución real del riesgo.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Análisis de métricas\n",
    "\n",
    "- **ROC AUC (0.758):** indica una buena capacidad discriminante del modelo.\n",
    "- **Recall clase 1 (0.63):** el modelo identifica correctamente cerca del 63% de los clientes riesgosos.\n",
    "- **Precision clase 1 (0.18):** valor esperado dado el fuerte desbalance de clases.\n",
    "- **Accuracy (0.74):** desempeño global aceptable, aunque no es la métrica principal.\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretación desde el punto de vista del negocio\n",
    "\n",
    "En el contexto del riesgo crediticio:\n",
    "\n",
    "- Es preferible identificar clientes con alto riesgo, aunque se generen falsos positivos.\n",
    "- Se prioriza el Recall sobre la Precision para la clase positiva.\n",
    "- El modelo cumple adecuadamente con este criterio de negocio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae411220",
   "metadata": {},
   "source": [
    "# Entrenamiento con Random Forest ajustado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d21a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar X e y\n",
    "X = data_set_base.drop(columns=[\"TARGET\", \"SK_ID_CURR\"])\n",
    "y = data_set_base[\"TARGET\"]\n",
    "\n",
    "# Train / Test estratificado\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Modelo Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=50,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Probabilidades\n",
    "y_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ROC AUC base\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(\"ROC AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc35e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_umbral(y_true, y_proba, threshold):\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    return {\n",
    "        \"umbral\": threshold,\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision_1\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall_1\": recall_score(y_true, y_pred),\n",
    "        \"f1_1\": f1_score(y_true, y_pred)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1920bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "umbrales = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for u in umbrales:\n",
    "    res = evaluar_umbral(y_test, y_proba, u)\n",
    "    resultados.append(res)\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542745d5",
   "metadata": {},
   "source": [
    "### Observaciones\n",
    "El ajuste de umbral evidenció que el Random Forest, sin corrección por desbalance, presenta una fuerte tendencia a clasificar la clase mayoritaria. Aunque alcanza un ROC AUC elevado, su desempeño operativo en detección de morosidad es limitado si no se ajusta el umbral o el peso de clases. Esto demuestra la importancia de evaluar modelos más allá de la accuracy y de adaptar el criterio de decisión al contexto del negocio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e2f6d7",
   "metadata": {},
   "source": [
    "## Entrenamiendo de Random Forest con class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_balanced = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=50,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "rf_balanced.fit(X_train, y_train)\n",
    "\n",
    "y_proba_rf_bal = rf_balanced.predict_proba(X_test)[:, 1]\n",
    "y_pred_rf_bal = (y_proba_rf_bal >= 0.5).astype(int)\n",
    "\n",
    "print(\"=== Random Forest (class_weight='balanced') ===\")\n",
    "print(classification_report(y_test, y_pred_rf_bal))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_rf_bal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53188dbf",
   "metadata": {},
   "source": [
    "## Entrenamiento de Random Forest con SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b77ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar SMOTE SOLO en entrenamiento\n",
    "smote = SMOTE(\n",
    "    sampling_strategy=0.5,   # no 1.0 para evitar overfitting\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Distribución original:\", y_train.value_counts())\n",
    "print(\"Distribución tras SMOTE:\", pd.Series(y_train_sm).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1960b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_smote = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=50,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_smote.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "y_proba_rf_smote = rf_smote.predict_proba(X_test)[:, 1]\n",
    "y_pred_rf_smote = (y_proba_rf_smote >= 0.5).astype(int)\n",
    "\n",
    "print(\"=== Random Forest + SMOTE ===\")\n",
    "print(classification_report(y_test, y_pred_rf_smote))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_rf_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f04402",
   "metadata": {},
   "outputs": [],
   "source": [
    "umbrales = [0.3, 0.4, 0.5]\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for u in umbrales:\n",
    "    y_pred_u = (y_proba_rf_smote >= u).astype(int)\n",
    "    resultados.append({\n",
    "        \"umbral\": u,\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred_u),\n",
    "        \"precision_1\": precision_score(y_test, y_pred_u, zero_division=0),\n",
    "        \"recall_1\": recall_score(y_test, y_pred_u),\n",
    "        \"f1_1\": f1_score(y_test, y_pred_u)\n",
    "    })\n",
    "\n",
    "pd.DataFrame(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a54e9af",
   "metadata": {},
   "source": [
    "# Entrenamiento de GradientBoostingClassifier, XGBoost y LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a584104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_set_base.drop(columns=[\"TARGET\", \"SK_ID_CURR\"])\n",
    "y = data_set_base[\"TARGET\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2332b66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Gradient Boosting ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     70672\n",
      "           1       0.66      0.02      0.03      6206\n",
      "\n",
      "    accuracy                           0.92     76878\n",
      "   macro avg       0.79      0.51      0.50     76878\n",
      "weighted avg       0.90      0.92      0.88     76878\n",
      "\n",
      "ROC AUC: 0.7681456056022673\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gb.predict(X_test)\n",
    "y_proba = gb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Gradient Boosting ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "073a7237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.72      0.82     70672\n",
      "           1       0.18      0.69      0.28      6206\n",
      "\n",
      "    accuracy                           0.72     76878\n",
      "   macro avg       0.57      0.71      0.55     76878\n",
      "weighted avg       0.90      0.72      0.78     76878\n",
      "\n",
      "ROC AUC: 0.7757039145806082\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),\n",
    "    eval_metric=\"auc\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_proba = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== XGBoost ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504c2b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 18619, number of negative: 212014\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0,030288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13725\n",
      "[LightGBM] [Info] Number of data points in the train set: 230633, number of used features: 98\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0,500000 -> initscore=-0,000000\n",
      "[LightGBM] [Info] Start training from score -0,000000\n",
      "=== LightGBM ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.73      0.83     70672\n",
      "           1       0.18      0.68      0.29      6206\n",
      "\n",
      "    accuracy                           0.73     76878\n",
      "   macro avg       0.57      0.71      0.56     76878\n",
      "weighted avg       0.90      0.73      0.79     76878\n",
      "\n",
      "ROC AUC: 0.7770620586634229\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=-1,\n",
    "    num_leaves=31,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgbm.predict(X_test)\n",
    "y_proba = lgbm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== LightGBM ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91223b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([\n",
    "    {\"Modelo\": \"Logistic Regression\", \"ROC_AUC\": 0.63},\n",
    "    {\"Modelo\": \"Random Forest\", \"ROC_AUC\": 0.76},\n",
    "    {\"Modelo\": \"Gradient Boosting\", \"ROC_AUC\": gb_auc},\n",
    "    {\"Modelo\": \"XGBoost\", \"ROC_AUC\": xgb_auc},\n",
    "    {\"Modelo\": \"LightGBM\", \"ROC_AUC\": lgbm_auc},\n",
    "])\n",
    "\n",
    "results.sort_values(\"ROC_AUC\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6bf06b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelo_riesgo_crediticio_lgb.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lgbm, \"modelo_riesgo_crediticio_lgb.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
